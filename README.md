# torchscope
This is a neat plugin for scoping model in PyTorch. It is mainly based on the [pytorch-summary](https://github.com/sksq96/pytorch-summary) and [torchstat](https://github.com/Swall0w/torchstat).

## Installation

- Install via pip

```
$ pip install torchscope
```

- Install from source

```
$ pip install --upgrade git+https://github.com/Tramac/torchscope.git
```

## Usage

```python
from torchvision.models import resnet18
from torchscope import scope

model = resnet18()
scope(model, input_size=(3, 224, 224))
```

```
------------------------------------------------------------------------------------------------------------------------------------
        Layer (type)               Output Shape          Params           FLOPs    Memory (MBs)     Energy (pJ)
====================================================================================================================================
            Conv2d-1          [2, 64, 112, 112]           9,408     118,013,952           12.36     271440000.00
       BatchNorm2d-2          [2, 64, 112, 112]             128       1,605,632           12.25       3700794.50
              ReLU-3          [2, 64, 112, 112]               0         802,816           12.25       1854316.80
         MaxPool2d-4            [2, 64, 56, 56]               0         802,816            3.06       1848436.80
            Conv2d-5            [2, 64, 56, 56]          36,864     115,605,504            3.48     265894880.00
       BatchNorm2d-6            [2, 64, 56, 56]             128         401,408            3.06        925199.31
              ReLU-7            [2, 64, 56, 56]               0         200,704            3.06        463579.20
            Conv2d-8            [2, 64, 56, 56]          36,864     115,605,504            3.48     265894880.00
       BatchNorm2d-9            [2, 64, 56, 56]             128         401,408            3.06        925199.31
             ReLU-10            [2, 64, 56, 56]               0         200,704            3.06        463579.20
           Conv2d-11            [2, 64, 56, 56]          36,864     115,605,504            3.48     265894880.00
      BatchNorm2d-12            [2, 64, 56, 56]             128         401,408            3.06        925199.31
             ReLU-13            [2, 64, 56, 56]               0         200,704            3.06        463579.20
           Conv2d-14            [2, 64, 56, 56]          36,864     115,605,504            3.48     265894880.00
      BatchNorm2d-15            [2, 64, 56, 56]             128         401,408            3.06        925199.31
             ReLU-16            [2, 64, 56, 56]               0         200,704            3.06        463579.20
           Conv2d-17           [2, 128, 28, 28]          73,728      57,802,752            2.38     132947848.00
      BatchNorm2d-18           [2, 128, 28, 28]             256         200,704            1.53        462601.06
             ReLU-19           [2, 128, 28, 28]               0         100,352            1.53        231789.60
           Conv2d-20           [2, 128, 28, 28]         147,456     115,605,504            3.22     265894720.00
      BatchNorm2d-21           [2, 128, 28, 28]             256         200,704            1.53        462601.06
           Conv2d-22           [2, 128, 28, 28]           8,192       6,422,528            1.62      14772854.00
      BatchNorm2d-23           [2, 128, 28, 28]             256         200,704            1.53        462601.06
             ReLU-24           [2, 128, 28, 28]               0         100,352            1.53        231789.60
           Conv2d-25           [2, 128, 28, 28]         147,456     115,605,504            3.22     265894720.00
      BatchNorm2d-26           [2, 128, 28, 28]             256         200,704            1.53        462601.06
             ReLU-27           [2, 128, 28, 28]               0         100,352            1.53        231789.60
           Conv2d-28           [2, 128, 28, 28]         147,456     115,605,504            3.22     265894720.00
      BatchNorm2d-29           [2, 128, 28, 28]             256         200,704            1.53        462601.06
             ReLU-30           [2, 128, 28, 28]               0         100,352            1.53        231789.60
           Conv2d-31           [2, 256, 14, 14]         294,912      57,802,752            4.14     132948976.00
      BatchNorm2d-32           [2, 256, 14, 14]             512         100,352            0.77        231303.34
             ReLU-33           [2, 256, 14, 14]               0          50,176            0.77        115894.80
           Conv2d-34           [2, 256, 14, 14]         589,824     115,605,504            7.52     265897472.00
      BatchNorm2d-35           [2, 256, 14, 14]             512         100,352            0.77        231303.34
           Conv2d-36           [2, 256, 14, 14]          32,768       6,422,528            1.14      14772544.00
      BatchNorm2d-37           [2, 256, 14, 14]             512         100,352            0.77        231303.34
             ReLU-38           [2, 256, 14, 14]               0          50,176            0.77        115894.80
           Conv2d-39           [2, 256, 14, 14]         589,824     115,605,504            7.52     265897472.00
      BatchNorm2d-40           [2, 256, 14, 14]             512         100,352            0.77        231303.34
             ReLU-41           [2, 256, 14, 14]               0          50,176            0.77        115894.80
           Conv2d-42           [2, 256, 14, 14]         589,824     115,605,504            7.52     265897472.00
      BatchNorm2d-43           [2, 256, 14, 14]             512         100,352            0.77        231303.34
             ReLU-44           [2, 256, 14, 14]               0          50,176            0.77        115894.80
           Conv2d-45             [2, 512, 7, 7]       1,179,648      57,802,752           13.88     132955216.00
      BatchNorm2d-46             [2, 512, 7, 7]           1,024          50,176            0.39        115657.30
             ReLU-47             [2, 512, 7, 7]               0          25,088            0.38         57947.40
           Conv2d-48             [2, 512, 7, 7]       2,359,296     115,605,504           27.38     265910176.00
      BatchNorm2d-49             [2, 512, 7, 7]           1,024          50,176            0.39        115657.30
           Conv2d-50             [2, 512, 7, 7]         131,072       6,422,528            1.88      14773019.00
      BatchNorm2d-51             [2, 512, 7, 7]           1,024          50,176            0.39        115657.30
             ReLU-52             [2, 512, 7, 7]               0          25,088            0.38         57947.40
           Conv2d-53             [2, 512, 7, 7]       2,359,296     115,605,504           27.38     265910176.00
      BatchNorm2d-54             [2, 512, 7, 7]           1,024          50,176            0.39        115657.30
             ReLU-55             [2, 512, 7, 7]               0          25,088            0.38         57947.40
           Conv2d-56             [2, 512, 7, 7]       2,359,296     115,605,504           27.38     265910176.00
      BatchNorm2d-57             [2, 512, 7, 7]           1,024          50,176            0.39        115657.30
             ReLU-58             [2, 512, 7, 7]               0          25,088            0.38         57947.40
AdaptiveAvgPool2d-59             [2, 512, 1, 1]               0               0            0.01             5.00
           Linear-60                  [2, 1000]         513,000         512,000            5.89       1181367.12
====================================================================================================================================
Total params: 11,689,512
Trainable params: 11,689,512
Non-trainable params: 0
====================================================================================================================================
Total Giga-FLOPs (GFLOPs): 1.82
----------------------------------------------------------------
Total Size (MBs): 248.45
----------------------------------------------------------------
Total Energy (mJ): 4.19
----------------------------------------------------------------
```

## Note

This plugin only supports the following operations:

-  Conv2d
- BatchNorm2d
- Pool2d
- ReLU
- Upsample

## Reference

- [pytorch-summary](https://github.com/sksq96/pytorch-summary)
- [torchstat](https://github.com/Swall0w/torchstat)